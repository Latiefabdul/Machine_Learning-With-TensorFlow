{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Latiefabdul/Machine_Learning-With_TensorFlow/blob/main/Final_Exam%204%20%3A%20Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tit-wZGOvhYI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oYciaUFIx64x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e740f119-c366-4e40-d73a-03eb99981c44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "data = open('/content/drive/MyDrive/poem.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)\n",
        "\n",
        "print(max_sequence_len)"
      ],
      "metadata": {
        "id": "gMRo6fwovkVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ccb93aa-ffc2-42c3-bfef-5507f72e35d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#buatlah model dengan output layer total words/2 dan total word\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "D0dSWWg7vmW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a73a5b3-c8db-4578-f1f3-c4f13f4c55bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 15, 100)           380800    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 15, 300)          301200    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 300)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               160400    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1904)              192304    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3808)              7254240   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,288,944\n",
            "Trainable params: 8,288,944\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gunakan loss categorical_crossentropy\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "4Pz9dFi5vo78"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training model \n",
        "history = model.fit(predictors, label, epochs=300, verbose=1)"
      ],
      "metadata": {
        "id": "cMCMd8U5ypod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95817d1-e70c-440d-859c-5b89d073c8da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "510/510 [==============================] - 88s 162ms/step - loss: 6.9675 - accuracy: 0.0612\n",
            "Epoch 2/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 6.5281 - accuracy: 0.0628\n",
            "Epoch 3/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 6.3628 - accuracy: 0.0649\n",
            "Epoch 4/300\n",
            "510/510 [==============================] - 86s 169ms/step - loss: 6.2447 - accuracy: 0.0681\n",
            "Epoch 5/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 6.1629 - accuracy: 0.0744\n",
            "Epoch 6/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 6.0969 - accuracy: 0.0776\n",
            "Epoch 7/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 6.0277 - accuracy: 0.0812\n",
            "Epoch 8/300\n",
            "510/510 [==============================] - 86s 169ms/step - loss: 5.9375 - accuracy: 0.0890\n",
            "Epoch 9/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 5.8400 - accuracy: 0.0967\n",
            "Epoch 10/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 5.7470 - accuracy: 0.1052\n",
            "Epoch 11/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 5.6678 - accuracy: 0.1083\n",
            "Epoch 12/300\n",
            "510/510 [==============================] - 86s 168ms/step - loss: 5.5951 - accuracy: 0.1117\n",
            "Epoch 13/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 5.5327 - accuracy: 0.1146\n",
            "Epoch 14/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 5.4660 - accuracy: 0.1180\n",
            "Epoch 15/300\n",
            "510/510 [==============================] - 86s 168ms/step - loss: 5.4009 - accuracy: 0.1223\n",
            "Epoch 16/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 5.3370 - accuracy: 0.1256\n",
            "Epoch 17/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 5.2737 - accuracy: 0.1292\n",
            "Epoch 18/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 5.2148 - accuracy: 0.1333\n",
            "Epoch 19/300\n",
            "510/510 [==============================] - 86s 169ms/step - loss: 5.1599 - accuracy: 0.1352\n",
            "Epoch 20/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 5.1045 - accuracy: 0.1376\n",
            "Epoch 21/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 5.0404 - accuracy: 0.1401\n",
            "Epoch 22/300\n",
            "510/510 [==============================] - 86s 168ms/step - loss: 4.9834 - accuracy: 0.1439\n",
            "Epoch 23/300\n",
            "510/510 [==============================] - 81s 160ms/step - loss: 4.9227 - accuracy: 0.1489\n",
            "Epoch 24/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 4.8675 - accuracy: 0.1531\n",
            "Epoch 25/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 4.8100 - accuracy: 0.1565\n",
            "Epoch 26/300\n",
            "510/510 [==============================] - 85s 166ms/step - loss: 4.7526 - accuracy: 0.1603\n",
            "Epoch 27/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 4.6922 - accuracy: 0.1628\n",
            "Epoch 28/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 4.6369 - accuracy: 0.1721\n",
            "Epoch 29/300\n",
            "510/510 [==============================] - 86s 168ms/step - loss: 4.5901 - accuracy: 0.1747\n",
            "Epoch 30/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 4.5232 - accuracy: 0.1810\n",
            "Epoch 31/300\n",
            "510/510 [==============================] - 81s 160ms/step - loss: 4.4608 - accuracy: 0.1863\n",
            "Epoch 32/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 4.4173 - accuracy: 0.1885\n",
            "Epoch 33/300\n",
            "510/510 [==============================] - 85s 167ms/step - loss: 4.3558 - accuracy: 0.1976\n",
            "Epoch 34/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 4.2960 - accuracy: 0.2024\n",
            "Epoch 35/300\n",
            "510/510 [==============================] - 81s 160ms/step - loss: 4.2434 - accuracy: 0.2104\n",
            "Epoch 36/300\n",
            "510/510 [==============================] - 85s 166ms/step - loss: 4.1808 - accuracy: 0.2153\n",
            "Epoch 37/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 4.1371 - accuracy: 0.2219\n",
            "Epoch 38/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 4.0848 - accuracy: 0.2270\n",
            "Epoch 39/300\n",
            "510/510 [==============================] - 86s 168ms/step - loss: 4.0315 - accuracy: 0.2346\n",
            "Epoch 40/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 3.9961 - accuracy: 0.2414\n",
            "Epoch 41/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 3.9422 - accuracy: 0.2487\n",
            "Epoch 42/300\n",
            "510/510 [==============================] - 85s 166ms/step - loss: 3.8841 - accuracy: 0.2598\n",
            "Epoch 43/300\n",
            "510/510 [==============================] - 81s 160ms/step - loss: 3.8409 - accuracy: 0.2652\n",
            "Epoch 44/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 3.7939 - accuracy: 0.2706\n",
            "Epoch 45/300\n",
            "510/510 [==============================] - 84s 165ms/step - loss: 3.7455 - accuracy: 0.2812\n",
            "Epoch 46/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 3.6927 - accuracy: 0.2899\n",
            "Epoch 47/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 3.6441 - accuracy: 0.2964\n",
            "Epoch 48/300\n",
            "510/510 [==============================] - 84s 165ms/step - loss: 3.6060 - accuracy: 0.3049\n",
            "Epoch 49/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 3.5547 - accuracy: 0.3131\n",
            "Epoch 50/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 3.5159 - accuracy: 0.3195\n",
            "Epoch 51/300\n",
            "510/510 [==============================] - 85s 166ms/step - loss: 3.4679 - accuracy: 0.3281\n",
            "Epoch 52/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 3.4237 - accuracy: 0.3402\n",
            "Epoch 53/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 3.3836 - accuracy: 0.3475\n",
            "Epoch 54/300\n",
            "510/510 [==============================] - 84s 164ms/step - loss: 3.3397 - accuracy: 0.3547\n",
            "Epoch 55/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 3.2977 - accuracy: 0.3616\n",
            "Epoch 56/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 3.2614 - accuracy: 0.3702\n",
            "Epoch 57/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 3.2164 - accuracy: 0.3808\n",
            "Epoch 58/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 3.1766 - accuracy: 0.3907\n",
            "Epoch 59/300\n",
            "510/510 [==============================] - 79s 154ms/step - loss: 3.1471 - accuracy: 0.3910\n",
            "Epoch 60/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 3.0991 - accuracy: 0.4045\n",
            "Epoch 61/300\n",
            "510/510 [==============================] - 83s 163ms/step - loss: 3.0727 - accuracy: 0.4078\n",
            "Epoch 62/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 3.0256 - accuracy: 0.4227\n",
            "Epoch 63/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 2.9873 - accuracy: 0.4295\n",
            "Epoch 64/300\n",
            "510/510 [==============================] - 84s 164ms/step - loss: 2.9647 - accuracy: 0.4334\n",
            "Epoch 65/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 2.9224 - accuracy: 0.4399\n",
            "Epoch 66/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 2.8879 - accuracy: 0.4501\n",
            "Epoch 67/300\n",
            "510/510 [==============================] - 84s 164ms/step - loss: 2.8468 - accuracy: 0.4596\n",
            "Epoch 68/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 2.8075 - accuracy: 0.4677\n",
            "Epoch 69/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 2.7889 - accuracy: 0.4717\n",
            "Epoch 70/300\n",
            "510/510 [==============================] - 84s 165ms/step - loss: 2.7600 - accuracy: 0.4789\n",
            "Epoch 71/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 2.7263 - accuracy: 0.4850\n",
            "Epoch 72/300\n",
            "510/510 [==============================] - 84s 164ms/step - loss: 2.6908 - accuracy: 0.4935\n",
            "Epoch 73/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 2.6563 - accuracy: 0.4997\n",
            "Epoch 74/300\n",
            "510/510 [==============================] - 83s 163ms/step - loss: 2.6291 - accuracy: 0.5049\n",
            "Epoch 75/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 2.6138 - accuracy: 0.5103\n",
            "Epoch 76/300\n",
            "510/510 [==============================] - 84s 164ms/step - loss: 2.5762 - accuracy: 0.5176\n",
            "Epoch 77/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 2.5439 - accuracy: 0.5236\n",
            "Epoch 78/300\n",
            "510/510 [==============================] - 84s 164ms/step - loss: 2.5072 - accuracy: 0.5331\n",
            "Epoch 79/300\n",
            "510/510 [==============================] - 80s 158ms/step - loss: 2.4899 - accuracy: 0.5393\n",
            "Epoch 80/300\n",
            "510/510 [==============================] - 83s 163ms/step - loss: 2.4483 - accuracy: 0.5458\n",
            "Epoch 81/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 2.4501 - accuracy: 0.5455\n",
            "Epoch 82/300\n",
            "510/510 [==============================] - 83s 163ms/step - loss: 2.4196 - accuracy: 0.5503\n",
            "Epoch 83/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 2.3731 - accuracy: 0.5618\n",
            "Epoch 84/300\n",
            "510/510 [==============================] - 83s 163ms/step - loss: 2.3545 - accuracy: 0.5679\n",
            "Epoch 85/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 2.3183 - accuracy: 0.5775\n",
            "Epoch 86/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 2.3001 - accuracy: 0.5770\n",
            "Epoch 87/300\n",
            "510/510 [==============================] - 83s 163ms/step - loss: 2.2901 - accuracy: 0.5798\n",
            "Epoch 88/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 2.2667 - accuracy: 0.5838\n",
            "Epoch 89/300\n",
            "510/510 [==============================] - 83s 163ms/step - loss: 2.2329 - accuracy: 0.5931\n",
            "Epoch 90/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 2.2243 - accuracy: 0.5906\n",
            "Epoch 91/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 2.1910 - accuracy: 0.5986\n",
            "Epoch 92/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 2.1793 - accuracy: 0.6008\n",
            "Epoch 93/300\n",
            "510/510 [==============================] - 82s 162ms/step - loss: 2.1470 - accuracy: 0.6095\n",
            "Epoch 94/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 2.1178 - accuracy: 0.6165\n",
            "Epoch 95/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 2.1135 - accuracy: 0.6131\n",
            "Epoch 96/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 2.1167 - accuracy: 0.6125\n",
            "Epoch 97/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 2.0698 - accuracy: 0.6189\n",
            "Epoch 98/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 2.0440 - accuracy: 0.6283\n",
            "Epoch 99/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 2.0206 - accuracy: 0.6334\n",
            "Epoch 100/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 2.0259 - accuracy: 0.6295\n",
            "Epoch 101/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 1.9997 - accuracy: 0.6336\n",
            "Epoch 102/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 1.9857 - accuracy: 0.6401\n",
            "Epoch 103/300\n",
            "510/510 [==============================] - 83s 163ms/step - loss: 1.9621 - accuracy: 0.6423\n",
            "Epoch 104/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 1.9362 - accuracy: 0.6469\n",
            "Epoch 105/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 1.9194 - accuracy: 0.6508\n",
            "Epoch 106/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 1.9137 - accuracy: 0.6550\n",
            "Epoch 107/300\n",
            "510/510 [==============================] - 82s 162ms/step - loss: 1.8857 - accuracy: 0.6569\n",
            "Epoch 108/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 1.8754 - accuracy: 0.6580\n",
            "Epoch 109/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 1.8554 - accuracy: 0.6692\n",
            "Epoch 110/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 1.8450 - accuracy: 0.6653\n",
            "Epoch 111/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 1.8302 - accuracy: 0.6700\n",
            "Epoch 112/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 1.8120 - accuracy: 0.6735\n",
            "Epoch 113/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 1.7993 - accuracy: 0.6746\n",
            "Epoch 114/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 1.7861 - accuracy: 0.6770\n",
            "Epoch 115/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 1.7778 - accuracy: 0.6795\n",
            "Epoch 116/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 1.7541 - accuracy: 0.6809\n",
            "Epoch 117/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 1.7533 - accuracy: 0.6817\n",
            "Epoch 118/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 1.7474 - accuracy: 0.6849\n",
            "Epoch 119/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 1.7106 - accuracy: 0.6938\n",
            "Epoch 120/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 1.6945 - accuracy: 0.6944\n",
            "Epoch 121/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 1.6790 - accuracy: 0.6961\n",
            "Epoch 122/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 1.6741 - accuracy: 0.6975\n",
            "Epoch 123/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 1.6703 - accuracy: 0.6999\n",
            "Epoch 124/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 1.6626 - accuracy: 0.7004\n",
            "Epoch 125/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 1.6354 - accuracy: 0.7029\n",
            "Epoch 126/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 1.6310 - accuracy: 0.7032\n",
            "Epoch 127/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 1.6178 - accuracy: 0.7063\n",
            "Epoch 128/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 1.5998 - accuracy: 0.7098\n",
            "Epoch 129/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 1.5904 - accuracy: 0.7142\n",
            "Epoch 130/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 1.6300 - accuracy: 0.7006\n",
            "Epoch 131/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 1.5845 - accuracy: 0.7131\n",
            "Epoch 132/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 1.5513 - accuracy: 0.7212\n",
            "Epoch 133/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 1.5497 - accuracy: 0.7187\n",
            "Epoch 134/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 1.5421 - accuracy: 0.7214\n",
            "Epoch 135/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 1.5212 - accuracy: 0.7264\n",
            "Epoch 136/300\n",
            "510/510 [==============================] - 79s 156ms/step - loss: 1.5137 - accuracy: 0.7249\n",
            "Epoch 137/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 1.5074 - accuracy: 0.7258\n",
            "Epoch 138/300\n",
            "510/510 [==============================] - 79s 156ms/step - loss: 1.4953 - accuracy: 0.7320\n",
            "Epoch 139/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 1.4887 - accuracy: 0.7302\n",
            "Epoch 140/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 1.4836 - accuracy: 0.7313\n",
            "Epoch 141/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 1.4738 - accuracy: 0.7309\n",
            "Epoch 142/300\n",
            "510/510 [==============================] - 83s 162ms/step - loss: 1.4573 - accuracy: 0.7350\n",
            "Epoch 143/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 1.4432 - accuracy: 0.7377\n",
            "Epoch 144/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 1.4349 - accuracy: 0.7401\n",
            "Epoch 145/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 1.4338 - accuracy: 0.7388\n",
            "Epoch 146/300\n",
            "510/510 [==============================] - 79s 155ms/step - loss: 1.4233 - accuracy: 0.7412\n",
            "Epoch 147/300\n",
            "510/510 [==============================] - 79s 155ms/step - loss: 1.4095 - accuracy: 0.7450\n",
            "Epoch 148/300\n",
            "510/510 [==============================] - 82s 161ms/step - loss: 1.4035 - accuracy: 0.7425\n",
            "Epoch 149/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 1.4037 - accuracy: 0.7456\n",
            "Epoch 150/300\n",
            "510/510 [==============================] - 79s 154ms/step - loss: 1.3874 - accuracy: 0.7503\n",
            "Epoch 151/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 1.3836 - accuracy: 0.7461\n",
            "Epoch 152/300\n",
            "510/510 [==============================] - 79s 154ms/step - loss: 1.3706 - accuracy: 0.7504\n",
            "Epoch 153/300\n",
            "510/510 [==============================] - 79s 154ms/step - loss: 1.3601 - accuracy: 0.7536\n",
            "Epoch 154/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 1.3614 - accuracy: 0.7529\n",
            "Epoch 155/300\n",
            "510/510 [==============================] - 79s 154ms/step - loss: 1.3490 - accuracy: 0.7537\n",
            "Epoch 156/300\n",
            "510/510 [==============================] - 79s 154ms/step - loss: 1.3415 - accuracy: 0.7556\n",
            "Epoch 157/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 1.3263 - accuracy: 0.7593\n",
            "Epoch 158/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 1.3285 - accuracy: 0.7600\n",
            "Epoch 159/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 1.3115 - accuracy: 0.7632\n",
            "Epoch 160/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 1.3130 - accuracy: 0.7593\n",
            "Epoch 161/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 1.3024 - accuracy: 0.7627\n",
            "Epoch 162/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 1.2973 - accuracy: 0.7675\n",
            "Epoch 163/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 1.2957 - accuracy: 0.7642\n",
            "Epoch 164/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 1.2819 - accuracy: 0.7664\n",
            "Epoch 165/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 1.2707 - accuracy: 0.7699\n",
            "Epoch 166/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 1.2732 - accuracy: 0.7676\n",
            "Epoch 167/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 1.3076 - accuracy: 0.7603\n",
            "Epoch 168/300\n",
            "510/510 [==============================] - 81s 160ms/step - loss: 1.2599 - accuracy: 0.7724\n",
            "Epoch 169/300\n",
            "510/510 [==============================] - 77s 150ms/step - loss: 1.2415 - accuracy: 0.7749\n",
            "Epoch 170/300\n",
            "510/510 [==============================] - 77s 151ms/step - loss: 1.2478 - accuracy: 0.7752\n",
            "Epoch 171/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 1.2394 - accuracy: 0.7745\n",
            "Epoch 172/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 1.2258 - accuracy: 0.7775\n",
            "Epoch 173/300\n",
            "510/510 [==============================] - 78s 152ms/step - loss: 1.2229 - accuracy: 0.7801\n",
            "Epoch 174/300\n",
            "510/510 [==============================] - 80s 158ms/step - loss: 1.2231 - accuracy: 0.7759\n",
            "Epoch 175/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 1.2060 - accuracy: 0.7826\n",
            "Epoch 176/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 1.2164 - accuracy: 0.7786\n",
            "Epoch 177/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 1.2169 - accuracy: 0.7759\n",
            "Epoch 178/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 1.2162 - accuracy: 0.7793\n",
            "Epoch 179/300\n",
            "510/510 [==============================] - 78s 152ms/step - loss: 1.1964 - accuracy: 0.7808\n",
            "Epoch 180/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 1.1848 - accuracy: 0.7866\n",
            "Epoch 181/300\n",
            "510/510 [==============================] - 78s 152ms/step - loss: 1.1781 - accuracy: 0.7860\n",
            "Epoch 182/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 1.1968 - accuracy: 0.7824\n",
            "Epoch 183/300\n",
            "510/510 [==============================] - 78s 152ms/step - loss: 1.2090 - accuracy: 0.7787\n",
            "Epoch 184/300\n",
            "510/510 [==============================] - 78s 152ms/step - loss: 1.1848 - accuracy: 0.7849\n",
            "Epoch 185/300\n",
            "510/510 [==============================] - 80s 158ms/step - loss: 1.1683 - accuracy: 0.7883\n",
            "Epoch 186/300\n",
            "510/510 [==============================] - 78s 152ms/step - loss: 1.1488 - accuracy: 0.7925\n",
            "Epoch 187/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 1.1567 - accuracy: 0.7901\n",
            "Epoch 188/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 1.1500 - accuracy: 0.7898\n",
            "Epoch 189/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 1.1455 - accuracy: 0.7914\n",
            "Epoch 190/300\n",
            "510/510 [==============================] - 77s 151ms/step - loss: 1.1407 - accuracy: 0.7916\n",
            "Epoch 191/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 1.1440 - accuracy: 0.7908\n",
            "Epoch 192/300\n",
            "510/510 [==============================] - 77s 152ms/step - loss: 1.1328 - accuracy: 0.7930\n",
            "Epoch 193/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 1.1140 - accuracy: 0.7979\n",
            "Epoch 194/300\n",
            "510/510 [==============================] - 77s 152ms/step - loss: 1.1119 - accuracy: 0.7971\n",
            "Epoch 195/300\n",
            "510/510 [==============================] - 77s 151ms/step - loss: 1.1107 - accuracy: 0.7976\n",
            "Epoch 196/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 1.1177 - accuracy: 0.7943\n",
            "Epoch 197/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 1.1195 - accuracy: 0.7970\n",
            "Epoch 198/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 1.1110 - accuracy: 0.7952\n",
            "Epoch 199/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 1.1072 - accuracy: 0.7984\n",
            "Epoch 200/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 1.0997 - accuracy: 0.7974\n",
            "Epoch 201/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 1.0960 - accuracy: 0.7988\n",
            "Epoch 202/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 1.0920 - accuracy: 0.8026\n",
            "Epoch 203/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 1.0874 - accuracy: 0.8031\n",
            "Epoch 204/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 1.0757 - accuracy: 0.8022\n",
            "Epoch 205/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 1.0762 - accuracy: 0.8033\n",
            "Epoch 206/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 1.0723 - accuracy: 0.8050\n",
            "Epoch 207/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 1.0863 - accuracy: 0.8002\n",
            "Epoch 208/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 1.0771 - accuracy: 0.8028\n",
            "Epoch 209/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 1.0685 - accuracy: 0.8055\n",
            "Epoch 210/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 1.0595 - accuracy: 0.8053\n",
            "Epoch 211/300\n",
            "510/510 [==============================] - 79s 154ms/step - loss: 1.0466 - accuracy: 0.8091\n",
            "Epoch 212/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 1.0468 - accuracy: 0.8095\n",
            "Epoch 213/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 1.0492 - accuracy: 0.8051\n",
            "Epoch 214/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 1.0545 - accuracy: 0.8080\n",
            "Epoch 215/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 1.0363 - accuracy: 0.8098\n",
            "Epoch 216/300\n",
            "510/510 [==============================] - 79s 154ms/step - loss: 1.0326 - accuracy: 0.8117\n",
            "Epoch 217/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 1.0310 - accuracy: 0.8094\n",
            "Epoch 218/300\n",
            "510/510 [==============================] - 78s 152ms/step - loss: 1.0373 - accuracy: 0.8085\n",
            "Epoch 219/300\n",
            "510/510 [==============================] - 77s 151ms/step - loss: 1.0274 - accuracy: 0.8131\n",
            "Epoch 220/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 1.0220 - accuracy: 0.8106\n",
            "Epoch 221/300\n",
            "510/510 [==============================] - 77s 152ms/step - loss: 1.0156 - accuracy: 0.8115\n",
            "Epoch 222/300\n",
            "510/510 [==============================] - 78s 152ms/step - loss: 1.0186 - accuracy: 0.8116\n",
            "Epoch 223/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 1.0220 - accuracy: 0.8101\n",
            "Epoch 224/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 1.0170 - accuracy: 0.8122\n",
            "Epoch 225/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 1.0081 - accuracy: 0.8123\n",
            "Epoch 226/300\n",
            "510/510 [==============================] - 78s 152ms/step - loss: 0.9992 - accuracy: 0.8172\n",
            "Epoch 227/300\n",
            "510/510 [==============================] - 78s 152ms/step - loss: 0.9976 - accuracy: 0.8148\n",
            "Epoch 228/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 1.0048 - accuracy: 0.8142\n",
            "Epoch 229/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 0.9910 - accuracy: 0.8180\n",
            "Epoch 230/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 0.9937 - accuracy: 0.8163\n",
            "Epoch 231/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 0.9992 - accuracy: 0.8129\n",
            "Epoch 232/300\n",
            "510/510 [==============================] - 79s 155ms/step - loss: 0.9870 - accuracy: 0.8154\n",
            "Epoch 233/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 0.9906 - accuracy: 0.8142\n",
            "Epoch 234/300\n",
            "510/510 [==============================] - 79s 155ms/step - loss: 0.9836 - accuracy: 0.8168\n",
            "Epoch 235/300\n",
            "510/510 [==============================] - 79s 155ms/step - loss: 0.9885 - accuracy: 0.8173\n",
            "Epoch 236/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 0.9740 - accuracy: 0.8190\n",
            "Epoch 237/300\n",
            "510/510 [==============================] - 79s 154ms/step - loss: 0.9787 - accuracy: 0.8184\n",
            "Epoch 238/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 0.9698 - accuracy: 0.8204\n",
            "Epoch 239/300\n",
            "510/510 [==============================] - 79s 154ms/step - loss: 0.9767 - accuracy: 0.8166\n",
            "Epoch 240/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 0.9730 - accuracy: 0.8202\n",
            "Epoch 241/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 0.9685 - accuracy: 0.8180\n",
            "Epoch 242/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 0.9704 - accuracy: 0.8155\n",
            "Epoch 243/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 0.9629 - accuracy: 0.8163\n",
            "Epoch 244/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 0.9396 - accuracy: 0.8259\n",
            "Epoch 245/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 0.9558 - accuracy: 0.8197\n",
            "Epoch 246/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 0.9537 - accuracy: 0.8209\n",
            "Epoch 247/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 0.9615 - accuracy: 0.8175\n",
            "Epoch 248/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 0.9518 - accuracy: 0.8197\n",
            "Epoch 249/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 0.9464 - accuracy: 0.8205\n",
            "Epoch 250/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 0.9403 - accuracy: 0.8229\n",
            "Epoch 251/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 0.9489 - accuracy: 0.8218\n",
            "Epoch 252/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 0.9422 - accuracy: 0.8213\n",
            "Epoch 253/300\n",
            "510/510 [==============================] - 81s 160ms/step - loss: 0.9456 - accuracy: 0.8217\n",
            "Epoch 254/300\n",
            "510/510 [==============================] - 79s 154ms/step - loss: 0.9372 - accuracy: 0.8235\n",
            "Epoch 255/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 0.9275 - accuracy: 0.8258\n",
            "Epoch 256/300\n",
            "510/510 [==============================] - 79s 155ms/step - loss: 0.9237 - accuracy: 0.8250\n",
            "Epoch 257/300\n",
            "510/510 [==============================] - 81s 160ms/step - loss: 0.9263 - accuracy: 0.8251\n",
            "Epoch 258/300\n",
            "510/510 [==============================] - 79s 155ms/step - loss: 0.9255 - accuracy: 0.8244\n",
            "Epoch 259/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 0.9308 - accuracy: 0.8229\n",
            "Epoch 260/300\n",
            "510/510 [==============================] - 79s 154ms/step - loss: 0.9354 - accuracy: 0.8225\n",
            "Epoch 261/300\n",
            "510/510 [==============================] - 81s 159ms/step - loss: 0.9361 - accuracy: 0.8220\n",
            "Epoch 262/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 0.9343 - accuracy: 0.8203\n",
            "Epoch 263/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 0.9263 - accuracy: 0.8231\n",
            "Epoch 264/300\n",
            "510/510 [==============================] - 81s 160ms/step - loss: 0.9291 - accuracy: 0.8232\n",
            "Epoch 265/300\n",
            "510/510 [==============================] - 79s 154ms/step - loss: 0.9119 - accuracy: 0.8261\n",
            "Epoch 266/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 0.9020 - accuracy: 0.8283\n",
            "Epoch 267/300\n",
            "510/510 [==============================] - 80s 158ms/step - loss: 0.8973 - accuracy: 0.8290\n",
            "Epoch 268/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 0.9120 - accuracy: 0.8251\n",
            "Epoch 269/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 0.9064 - accuracy: 0.8247\n",
            "Epoch 270/300\n",
            "510/510 [==============================] - 79s 155ms/step - loss: 0.9034 - accuracy: 0.8241\n",
            "Epoch 271/300\n",
            "510/510 [==============================] - 82s 160ms/step - loss: 0.9125 - accuracy: 0.8245\n",
            "Epoch 272/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 0.9025 - accuracy: 0.8287\n",
            "Epoch 273/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 0.9045 - accuracy: 0.8267\n",
            "Epoch 274/300\n",
            "510/510 [==============================] - 79s 154ms/step - loss: 0.9155 - accuracy: 0.8220\n",
            "Epoch 275/300\n",
            "510/510 [==============================] - 81s 160ms/step - loss: 0.9010 - accuracy: 0.8270\n",
            "Epoch 276/300\n",
            "510/510 [==============================] - 77s 150ms/step - loss: 0.9023 - accuracy: 0.8285\n",
            "Epoch 277/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 0.8946 - accuracy: 0.8277\n",
            "Epoch 278/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 0.9029 - accuracy: 0.8232\n",
            "Epoch 279/300\n",
            "510/510 [==============================] - 81s 158ms/step - loss: 0.8931 - accuracy: 0.8255\n",
            "Epoch 280/300\n",
            "510/510 [==============================] - 78s 154ms/step - loss: 0.8878 - accuracy: 0.8289\n",
            "Epoch 281/300\n",
            "510/510 [==============================] - 78s 153ms/step - loss: 0.8853 - accuracy: 0.8294\n",
            "Epoch 282/300\n",
            "510/510 [==============================] - 80s 158ms/step - loss: 0.8858 - accuracy: 0.8290\n",
            "Epoch 283/300\n",
            "510/510 [==============================] - 77s 151ms/step - loss: 0.8905 - accuracy: 0.8266\n",
            "Epoch 284/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 0.8952 - accuracy: 0.8269\n",
            "Epoch 285/300\n",
            "510/510 [==============================] - 76s 149ms/step - loss: 0.8853 - accuracy: 0.8286\n",
            "Epoch 286/300\n",
            "510/510 [==============================] - 76s 149ms/step - loss: 0.8973 - accuracy: 0.8250\n",
            "Epoch 287/300\n",
            "510/510 [==============================] - 79s 156ms/step - loss: 0.8823 - accuracy: 0.8272\n",
            "Epoch 288/300\n",
            "510/510 [==============================] - 77s 150ms/step - loss: 0.8736 - accuracy: 0.8305\n",
            "Epoch 289/300\n",
            "510/510 [==============================] - 79s 156ms/step - loss: 0.8737 - accuracy: 0.8299\n",
            "Epoch 290/300\n",
            "510/510 [==============================] - 77s 150ms/step - loss: 0.8903 - accuracy: 0.8259\n",
            "Epoch 291/300\n",
            "510/510 [==============================] - 77s 150ms/step - loss: 0.8853 - accuracy: 0.8254\n",
            "Epoch 292/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 0.8712 - accuracy: 0.8307\n",
            "Epoch 293/300\n",
            "510/510 [==============================] - 77s 150ms/step - loss: 0.8734 - accuracy: 0.8303\n",
            "Epoch 294/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 0.8666 - accuracy: 0.8304\n",
            "Epoch 295/300\n",
            "510/510 [==============================] - 77s 151ms/step - loss: 0.8742 - accuracy: 0.8275\n",
            "Epoch 296/300\n",
            "510/510 [==============================] - 80s 156ms/step - loss: 0.8716 - accuracy: 0.8288\n",
            "Epoch 297/300\n",
            "510/510 [==============================] - 77s 151ms/step - loss: 0.8772 - accuracy: 0.8273\n",
            "Epoch 298/300\n",
            "510/510 [==============================] - 77s 152ms/step - loss: 0.8659 - accuracy: 0.8304\n",
            "Epoch 299/300\n",
            "510/510 [==============================] - 80s 157ms/step - loss: 0.8664 - accuracy: 0.8296\n",
            "Epoch 300/300\n",
            "510/510 [==============================] - 77s 151ms/step - loss: 0.8731 - accuracy: 0.8286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "model.save('model4.h5')"
      ],
      "metadata": {
        "id": "XV8u3MEazbvP"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}